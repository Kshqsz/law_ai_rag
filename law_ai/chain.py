# coding: utf-8
"""
RAG é“¾å¼å¤„ç†æ¨¡å—ï¼šæž„å»ºå®Œæ•´çš„æ£€ç´¢å¢žå¼ºç”Ÿæˆ(RAG)ç®¡é“

åŠŸèƒ½è¯´æ˜Žï¼š
- LawStuffDocumentsChain: è‡ªå®šä¹‰çš„æ–‡æ¡£å¡«å……é“¾ï¼ˆç»§æ‰¿ StuffDocumentsChainï¼‰
  å°†æ£€ç´¢åˆ°çš„æ³•å¾‹æ–‡æ¡£å’Œç½‘é¡µå†…å®¹æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
  æŒ‰ç…§ä¹¦ç±å’Œæ¥æºåˆ†ç»„ç»„ç»‡å†…å®¹
  
- LawQAChain: æ³•å¾‹é—®ç­”é“¾ï¼ˆç»§æ‰¿ BaseRetrievalQAï¼‰
  åŒæ—¶ä»Žå‘é‡åº“å’Œç½‘é¡µè¿›è¡Œæ£€ç´¢
  åˆå¹¶ä¸¤ç§æ¥æºçš„æ–‡æ¡£
  ç”Ÿæˆæœ€ç»ˆçš„æ³•å¾‹é—®ç­”ç»“æžœ
  
- get_check_law_chain(config): åˆ›å»ºæ³•å¾‹ç›¸å…³æ€§æ£€æŸ¥é“¾
  åˆ¤æ–­é—®é¢˜æ˜¯å¦ä¸Žæ³•å¾‹ç›¸å…³
  
- get_law_chain(config, out_callback): åˆ›å»ºå®Œæ•´çš„æ³•å¾‹ RAG é“¾
  åˆå§‹åŒ–å‘é‡åº“ã€æ£€ç´¢å™¨ã€æ¨¡åž‹
  æ”¯æŒå¼‚æ­¥æµå¼è¾“å‡º
  æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•

ä½¿ç”¨ç¤ºä¾‹ï¼š
    from law_ai.chain import get_law_chain, get_check_law_chain
    from law_ai.callback import OutCallbackHandler
    import asyncio
    
    # åˆ›å»ºé…ç½®å¯¹è±¡ï¼ˆå‡è®¾ä»Ž config.py å¯¼å…¥ï¼‰
    from config import Config
    config = Config()
    
    # ç¤ºä¾‹ 1: æ£€æŸ¥é—®é¢˜æ˜¯å¦ä¸Žæ³•å¾‹ç›¸å…³
    check_chain = get_check_law_chain(config)
    is_law_related = check_chain.invoke({"question": "ä»€ä¹ˆæ˜¯æ°‘æ³•å…¸ï¼Ÿ"})
    print(f"ä¸Žæ³•å¾‹ç›¸å…³: {is_law_related}")  # è¾“å‡º: ä¸Žæ³•å¾‹ç›¸å…³: True
    
    # ç¤ºä¾‹ 2: ä½¿ç”¨å®Œæ•´çš„ RAG é“¾è¿›è¡Œæ³•å¾‹é—®ç­”
    callback = OutCallbackHandler()
    chain = get_law_chain(config, callback)
    
    # åŒæ­¥è°ƒç”¨
    result = chain.invoke({
        "query": "åˆåŒçš„è¿çº¦è´£ä»»å¦‚ä½•å¤„ç†ï¼Ÿ"
    })
    print(f"ç­”æ¡ˆ: {result['output_text']}")
    
    # å¼‚æ­¥è°ƒç”¨ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
    async def ask_law_question(question: str):
        callback = OutCallbackHandler()
        chain = get_law_chain(config, callback)
        
        result = await chain.ainvoke({
            "query": question
        })
        return result
    
    # è¿è¡Œå¼‚æ­¥è°ƒç”¨
    # result = asyncio.run(ask_law_question("æ°‘æ³•å…¸ä¸­ä»€ä¹ˆæ˜¯åˆåŒï¼Ÿ"))
    
    # æ—¥å¿—è¾“å‡ºç¤ºä¾‹ï¼š
    # [INFO] [Chain] ðŸ”§ åˆå§‹åŒ–æ³•å¾‹ RAG Chain...
    # [INFO] [Chain] âœ“ å‘é‡åº“åŠ è½½å®Œæˆ
    # [INFO] [Chain] âœ“ æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ (ä»£ç†: http://127.0.0.1:7890)
    # [INFO] [Chain] âœ“ å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ
    # [INFO] [Chain] ðŸ“š å¼€å§‹æ£€ç´¢æ³•å¾‹æ–‡çŒ®...
    # [INFO] [Retriever] ðŸ” å¼€å§‹å‘é‡æ£€ç´¢...
    # [INFO] [Retriever] âœ“ å‘é‡æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° 3 æ¡æ³•å¾‹æ–‡æ¡£
    # [INFO] [Chain] ðŸŒ å¼€å§‹æ£€ç´¢ç½‘é¡µèµ„æº...
    # [INFO] [Retriever] ðŸ” å¼€å§‹ç½‘é¡µæœç´¢...
    # [INFO] [Retriever] âœ“ ç½‘é¡µæœç´¢æˆåŠŸ
    # [INFO] [Chain] ðŸ“– å…±æ£€ç´¢åˆ° 4 æ¡èµ„æ–™
"""
from typing import Any, Optional, List
from collections import defaultdict
from operator import itemgetter

from langchain.chains.retrieval_qa.base import BaseRetrievalQA
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.schema.language_model import BaseLanguageModel
from langchain.prompts import PromptTemplate
from langchain.callbacks.manager import Callbacks
from langchain.chains.question_answering.stuff_prompt import PROMPT_SELECTOR
from langchain.chains.llm import LLMChain
from langchain.docstore.document import Document
from langchain.schema import format_document
from langchain.schema import BaseRetriever
from langchain.pydantic_v1 import Field
from langchain.schema.output_parser import StrOutputParser
from langchain.output_parsers import BooleanOutputParser
from langchain.schema.runnable import RunnableMap
from langchain.chains.base import Chain
from langchain.callbacks import AsyncIteratorCallbackHandler
from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser
from langchain.callbacks.manager import (
    AsyncCallbackManagerForChainRun,
    CallbackManagerForChainRun,
)

from .utils import get_vectorstore, get_model
from .retriever import LawWebRetiever, ProxyDuckDuckGoSearch, get_multi_query_law_retiever
from .prompt import LAW_PROMPT, CHECK_LAW_PROMPT, HYPO_QUESTION_PROMPT
from .combine import combine_law_docs, combine_web_docs
from .logger import chain_logger


class LawStuffDocumentsChain(StuffDocumentsChain):
    def _get_inputs(self, docs: List[Document], **kwargs: Any) -> dict:
        # Join the documents together to put them in the prompt.
        law_book = defaultdict(list)
        law_web = defaultdict(list)
        for doc in docs:
            metadata = doc.metadata
            if 'book' in metadata:
                law_book[metadata["book"]].append(
                    format_document(doc, self.document_prompt).strip("\n"))
            elif 'link' in metadata:
                law_web[metadata["title"]].append(
                    format_document(doc, self.document_prompt).strip("\n"))

        law_str = ""
        for book, page_contents in law_book.items():
            law_str += f"ã€Š{book}ã€‹\n"
            law_str += "\n".join(page_contents)
            law_str += "\n\n"

        for web, page_contents in law_web.items():
            law_str += f"ç½‘é¡µï¼š{web}\n"
            law_str += "\n".join(page_contents)
            law_str += "\n\n"

        inputs = {
            k: v
            for k, v in kwargs.items()
            if k in self.llm_chain.prompt.input_variables
        }
        inputs[self.document_variable_name] = law_str
        return inputs


class LawQAChain(BaseRetrievalQA):
    vs_retriever: BaseRetriever = Field(exclude=True)
    web_retriever: BaseRetriever = Field(exclude=True)

    def _get_docs(
        self,
        question: str,
        *,
        run_manager: CallbackManagerForChainRun,
    ) -> List[Document]:
        """Get docs."""
        chain_logger.info(f"ðŸ“š å¼€å§‹æ£€ç´¢æ³•å¾‹æ–‡çŒ®...")
        vs_docs = self.vs_retriever.get_relevant_documents(
            question, callbacks=run_manager.get_child()
        )
        chain_logger.info(f"âœ“ æ³•å¾‹æ–‡çŒ®æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(vs_docs)} æ¡ç›¸å…³æ–‡æ¡£")

        chain_logger.info(f"ðŸŒ å¼€å§‹æ£€ç´¢ç½‘é¡µèµ„æº...")
        web_docs = self.web_retriever.get_relevant_documents(
            question, callbacks=run_manager.get_child()
        )
        chain_logger.info(f"âœ“ ç½‘é¡µèµ„æºæ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(web_docs)} æ¡ç›¸å…³èµ„æº")

        total_docs = vs_docs + web_docs
        chain_logger.info(f"ðŸ“– å…±æ£€ç´¢åˆ° {len(total_docs)} æ¡èµ„æ–™")
        return total_docs

    async def _aget_docs(
        self,
        question: str,
        *,
        run_manager: AsyncCallbackManagerForChainRun,
    ) -> List[Document]:
        """Get docs."""
        chain_logger.info(f"ðŸ“š å¼€å§‹æ£€ç´¢æ³•å¾‹æ–‡çŒ®...")
        vs_docs = await self.vs_retriever.aget_relevant_documents(
            question, callbacks=run_manager.get_child()
        )
        chain_logger.info(f"âœ“ æ³•å¾‹æ–‡çŒ®æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(vs_docs)} æ¡ç›¸å…³æ–‡æ¡£")

        chain_logger.info(f"ðŸŒ å¼€å§‹æ£€ç´¢ç½‘é¡µèµ„æº...")
        web_docs = await self.web_retriever.aget_relevant_documents(
            question, callbacks=run_manager.get_child()
        )
        chain_logger.info(f"âœ“ ç½‘é¡µèµ„æºæ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(web_docs)} æ¡ç›¸å…³èµ„æº")

        total_docs = vs_docs + web_docs
        chain_logger.info(f"ðŸ“– å…±æ£€ç´¢åˆ° {len(total_docs)} æ¡èµ„æ–™")
        return total_docs

    @property
    def _chain_type(self) -> str:
        """Return the chain type."""
        return "law_qa"

    @classmethod
    def from_llm(
        cls,
        llm: BaseLanguageModel,
        prompt: Optional[PromptTemplate] = None,
        callbacks: Callbacks = None,
        **kwargs: Any,
    ) -> BaseRetrievalQA:
        """Initialize from LLM."""
        _prompt = prompt or PROMPT_SELECTOR.get_prompt(llm)
        llm_chain = LLMChain(llm=llm, prompt=_prompt, callbacks=callbacks)
        document_prompt = PromptTemplate(
            input_variables=["page_content"], template="{page_content}"
        )

        combine_documents_chain = LawStuffDocumentsChain(
            llm_chain=llm_chain,
            document_variable_name="context",
            document_prompt=document_prompt,
            callbacks=callbacks,
        )

        return cls(
            combine_documents_chain=combine_documents_chain,
            callbacks=callbacks,
            **kwargs,
        )


def get_check_law_chain(config: Any) -> Chain:
    model = get_model()

    check_chain = CHECK_LAW_PROMPT | model | BooleanOutputParser()

    return check_chain


def get_law_chain(config: Any, out_callback: AsyncIteratorCallbackHandler) -> Chain:
    chain_logger.info("ðŸ”§ åˆå§‹åŒ–æ³•å¾‹ RAG Chain...")
    
    law_vs = get_vectorstore(config.LAW_VS_COLLECTION_NAME)
    web_vs = get_vectorstore(config.WEB_VS_COLLECTION_NAME)
    chain_logger.info("âœ“ å‘é‡åº“åŠ è½½å®Œæˆ")

    vs_retriever = law_vs.as_retriever(search_kwargs={"k": config.LAW_VS_SEARCH_K})
    
    # ä½¿ç”¨ä»£ç†é…ç½®
    proxy = getattr(config, 'WEB_PROXY', None)
    web_retriever = LawWebRetiever(
        vectorstore=web_vs,
        search=ProxyDuckDuckGoSearch(proxy=proxy),
        num_search_results=config.WEB_VS_SEARCH_K
    )
    chain_logger.info(f"âœ“ æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ (ä»£ç†: {proxy or 'æ— '})")

    multi_query_retriver = get_multi_query_law_retiever(vs_retriever, get_model())
    chain_logger.info("âœ“ å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")

    callbacks = [out_callback] if out_callback else []

    def log_law_docs(x):
        """è®°å½•æ³•å¾‹æ–‡æ¡£æ£€ç´¢ç»“æžœ"""
        law_docs = x["law_docs"]
        chain_logger.info(f"ðŸ“š å‘é‡åº“æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(law_docs)} æ¡æ³•å¾‹æ–‡æ¡£:")
        for i, doc in enumerate(law_docs, 1):
            book = doc.metadata.get('book', 'æœªçŸ¥')
            content_preview = doc.page_content[:80].replace('\n', ' ')
            chain_logger.info(f"  ðŸ“– [{i}] ã€Š{book}ã€‹: {content_preview}...")
        return law_docs
    
    def log_web_docs(x):
        """è®°å½•ç½‘é¡µæ£€ç´¢ç»“æžœ"""
        web_docs = x["web_docs"]
        if web_docs:
            chain_logger.info(f"ðŸŒ ç½‘é¡µæ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(web_docs)} æ¡ç½‘é¡µèµ„æº")
        return web_docs
    
    def log_prompt_and_call_llm(x):
        """è®°å½• prompt å¹¶è°ƒç”¨å¤§æ¨¡åž‹"""
        law_context = x["law_context"]
        web_context = x["web_context"]
        question = x["question"]
        
        chain_logger.info("=" * 60)
        chain_logger.info("ðŸ“ å‘é€ç»™å¤§æ¨¡åž‹çš„ Prompt:")
        chain_logger.info(f"  ç”¨æˆ·é—®é¢˜: {question}")
        chain_logger.info(f"  æ³•å¾‹ä¸Šä¸‹æ–‡ ({len(law_context)} å­—ç¬¦):")
        # åªæ˜¾ç¤ºå‰ 500 å­—ç¬¦
        preview = law_context[:500].replace('\n', '\n    ')
        chain_logger.info(f"    {preview}...")
        if web_context:
            chain_logger.info(f"  ç½‘é¡µä¸Šä¸‹æ–‡ ({len(web_context)} å­—ç¬¦)")
        chain_logger.info("=" * 60)
        chain_logger.info("ðŸ¤– è°ƒç”¨å¤§æ¨¡åž‹ç”Ÿæˆç­”æ¡ˆ...")
        
        # æ ¼å¼åŒ– prompt å¹¶è°ƒç”¨æ¨¡åž‹
        prompt = LAW_PROMPT
        answer_chain = prompt | get_model(callbacks=callbacks) | StrOutputParser()
        return answer_chain.invoke(x)

    chain = (
        RunnableMap(
            {
                "law_docs": itemgetter("question") | multi_query_retriver,
                'web_docs': itemgetter("question") | web_retriever,
                "question": lambda x: x["question"]}
        )
        | RunnableMap(
            {
                "law_docs": log_law_docs,
                "web_docs": log_web_docs,
                "law_context": lambda x: combine_law_docs(x["law_docs"]),
                "web_context": lambda x: combine_web_docs(x["web_docs"]),
                "question": lambda x: x["question"]}
        )
        | RunnableMap({
            "law_docs": lambda x: x["law_docs"],
            "web_docs": lambda x: x["web_docs"],
            "law_context": lambda x: x["law_context"],
            "web_context": lambda x: x["web_context"],
            "question": lambda x: x["question"],
            "answer": log_prompt_and_call_llm
        })
    )

    return chain


def get_hypo_questions_chain(config: Any) -> Chain:
    model = get_model()

    functions = [
        {
            "name": "hypothetical_questions",
            "description": "Generate hypothetical questions",
            "parameters": {
                "type": "object",
                "properties": {
                    "questions": {
                        "type": "array",
                        "items": {
                            "type": "string"
                        },
                    },
                },
                "required": ["questions"]
            }
        }
    ]

    chain = (
        {"context": lambda x: f"ã€Š{x.metadata['book']}ã€‹{x.page_content}"}
        | HYPO_QUESTION_PROMPT
        | model.bind(functions=functions, function_call={"name": "hypothetical_questions"})
        | JsonKeyOutputFunctionsParser(key_name="questions")
    )

    return chain